{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chess\n",
    "import chess.pgn\n",
    "from chess.engine import PovScore, Cp\n",
    "from io import StringIO,TextIOWrapper\n",
    "import h5py\n",
    "import sys\n",
    "import zstandard as zstd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the data in several stages.\n",
    "\n",
    "1. Extract valid games (see below) into pgn files using string operations.\n",
    "2. Create different hdf5 files for training, validation and testing containing (game,label) tensors for different time controls from multiple pgn files, filtering out invalid games using the python chess library.\n",
    "3. Create oversampled training files.\n",
    "\n",
    "Valid game files are based on the `TimeControl \"{a time control}\"` field, whether the term `[%eval` is in the string and whether `BlackRatingDiff` and `WhiteRatingDiff` is below a certain value as well as whether `Termination` is *not* `Abandoned` or `Rules nfraction`.\n",
    "\n",
    "If all the above conditions are met we utilise the `Board` class to parse the pgn, also checking that game length is above some minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stores a time-control:file string. The time-control is a regex string that matches the time-control of a game. The file string is the name of the file that the game should be saved to.\n",
    "\n",
    "file_dict = {\"300+0\":\"blitz\",\n",
    "             \"300+3\":\"blitz\",\n",
    "             \"60+0\":\"ultrabullet\",\n",
    "             \"120+1\":\"bullet\",\n",
    "             \"180+0\":\"superblitz\",\n",
    "             \"180+2\":\"superblitz\",\n",
    "             \"600+0\":\"rapid\",\n",
    "             \"600+5\":\"rapid\",\n",
    "             \"900+10\":\"rapid\"\n",
    "}\n",
    "\n",
    "#the maximum rating diff above which we ignore the game\n",
    "MAX_RATING_DIFF = 40\n",
    "\n",
    "#Termination strings that we ignore\n",
    "TERMINATION_STRINGS=set([\"Abandoned\",\"Rules infraction\"])\n",
    "\n",
    "NUM_MOVES = 40 #number of moves to consider for each game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_tensor(game_string):\n",
    "    \"\"\"returns a tensor representation of the game string. If the game is invalid, returns None. Note that a valid game will have 2 game tensors, one for each player. We also return the ratings of the players and the file that the game should be saved to.\"\"\"\n",
    "\n",
    "    #start by checking if the game is valid. The time control is a substring of the form 'TimeControl \"{TC}\"' where {TC} is a variable, check if {TC} is in the file_dict.\n",
    "\n",
    "    time_control = game_string.split('TimeControl \"')[1].split('\"')[0]\n",
    "    if time_control not in file_dict:\n",
    "        return None\n",
    "    \n",
    "    valid = False\n",
    "    \n",
    "    if '[%eval' in game_string and 'WhiteRatingDiff' in game_string and 'BlackRatingDiff' in game_string:\n",
    "        white_diff = int(game_string.split('WhiteRatingDiff \"')[1].split('\"')[0])\n",
    "        black_diff = int(game_string.split('BlackRatingDiff \"')[1].split('\"')[0])\n",
    "        if abs(white_diff) < MAX_RATING_DIFF and abs(black_diff) < MAX_RATING_DIFF:\n",
    "            valid = True\n",
    "    if not valid:\n",
    "        return None\n",
    "    \n",
    "    #check for termination strings\n",
    "    for term in TERMINATION_STRINGS:\n",
    "        if term in game_string:\n",
    "            return None\n",
    "    \n",
    "    ########prepare the game tensors\n",
    "    gt1 = np.zeros((NUM_MOVES,136),dtype=np.int16)\n",
    "    gt2 = np.zeros((NUM_MOVES,136),dtype=np.int16)\n",
    "\n",
    "    game = chess.pgn.read_game(StringIO(game_string))\n",
    "\n",
    "    board = game.board()\n",
    "    white_time = 0\n",
    "    black_time = 0\n",
    "\n",
    "    move_number = 0\n",
    "\n",
    "    current_eval = PovScore(Cp(0), chess.WHITE)\n",
    "    current_move_color = chess.WHITE\n",
    "    while True:\n",
    "        t = np.zeros(136)\n",
    "\n",
    "        for i in range(64):\n",
    "            if board.piece_at(i) is None:\n",
    "                t[i] = 0\n",
    "            elif board.piece_at(i).color == current_move_color:\n",
    "                t[i] = board.piece_at(i).piece_type\n",
    "            else:\n",
    "                t[i] = board.piece_at(i).piece_type + 7\n",
    "\n",
    "        # get the evaluation, time etc.\n",
    "        t[128] = move_number // 2  # move number\n",
    "\n",
    "        t[129] = white_time if current_move_color == chess.WHITE else black_time\n",
    "\n",
    "        t[131] = black_time if current_move_color == chess.WHITE else white_time\n",
    "\n",
    "        if current_eval is None: #mate in 0\n",
    "            t[135] = 1\n",
    "            t[134] = 0\n",
    "        elif current_eval.pov(current_move_color).is_mate(): #mate in X\n",
    "            t[133] = 1\n",
    "            t[132] = current_eval.pov(current_move_color).mate()\n",
    "        else:\n",
    "            t[133] = 0\n",
    "            t[132] = current_eval.pov(current_move_color).score()\n",
    "\n",
    "        if move_number == 0:\n",
    "            m = game.next()\n",
    "        else:\n",
    "            m = m.next()\n",
    "        if m is None:\n",
    "            break\n",
    "\n",
    "        if current_move_color == chess.WHITE:\n",
    "            white_time = m.clock()\n",
    "        else:\n",
    "            black_time = m.clock()\n",
    "\n",
    "        current_eval = m.eval()\n",
    "        board = m.board()\n",
    "\n",
    "        for i in range(64):\n",
    "            if board.piece_at(i) is None:\n",
    "                t[i + 64] = 0\n",
    "            elif board.piece_at(i).color == current_move_color:\n",
    "                t[i + 64] = board.piece_at(i).piece_type\n",
    "            else:\n",
    "                t[i + 64] = board.piece_at(i).piece_type + 7\n",
    "\n",
    "        t[130] = white_time if current_move_color == chess.WHITE else black_time\n",
    "\n",
    "        if current_eval is None:\n",
    "            t[135] = 1\n",
    "            t[134] = 0\n",
    "        elif current_eval.pov(current_move_color).is_mate():\n",
    "            t[135] = 1\n",
    "            t[134] = current_eval.pov(current_move_color).mate()\n",
    "        else:\n",
    "            t[135] = 0\n",
    "            t[134] = current_eval.pov(current_move_color).score()\n",
    "\n",
    "        if current_move_color == chess.WHITE:\n",
    "            gt1[move_number // 2] = t\n",
    "        else:\n",
    "            gt2[move_number // 2] = t\n",
    "\n",
    "        current_move_color = not current_move_color\n",
    "\n",
    "        move_number += 1\n",
    "\n",
    "        if move_number == NUM_MOVES * 2:\n",
    "            break\n",
    "\n",
    "    return np.array(gt1),np.array(gt2),int(game.headers['WhiteElo']),int(game.headers['BlackElo']),file_dict[time_control]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to read from an input file compressed using zst and write all the resultant game tensors and ratings to a hdf5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKSIZE = 1000\n",
    "\n",
    "def write_to_hdf5(reader):\n",
    "    \"\"\"writes the games in the reader to an hdf5 file. The reader is a generator that yields game strings. The games are stored in the file according to the time-control of the game. We will write the game tensors as a dataset in the file. We will also write the ratings of the players as a dataset in the file. The file will be named according to the time-control of the games.\"\"\"\n",
    "\n",
    "    #open all the files so that we don't have to keep doing it.\n",
    "    files = {}\n",
    "    for file_name in set(file_dict.values()):\n",
    "        files[file_name] = h5py.File(f\"{file_name}.hdf5\",\"a\") #5*10^8 bytes = 500MB for the cache for each file\n",
    "\n",
    "    file_indexes = {}\n",
    "    if files[file_name].get(\"game_tensors\") is not None:\n",
    "        file_indexes = {file_name:len(files[file_name][\"game_tensors\"]) for file_name in files}\n",
    "    else:\n",
    "        file_indexes = {file_name:0 for file_name in files}\n",
    "\n",
    "    game = \"\"\n",
    "    count = 0\n",
    "\n",
    "    for line in reader:\n",
    "        if line.startswith(\"[Event\") and game == \"\": #start of a new game when the file hasn't been initialized\n",
    "            game = line\n",
    "        elif line.startswith(\"[Event\") and game != \"\": #start of a new game when the file has been initialized, write the previous game to the file\n",
    "\n",
    "            if count % 1000 == 0:\n",
    "                print(\"read\",count,\"games\")\n",
    "            count += 1\n",
    "\n",
    "            game_tensors = get_game_tensor(game)\n",
    "            if game_tensors is None:\n",
    "                game = line\n",
    "                continue\n",
    "            else:\n",
    "                #print(\"read game\",game)\n",
    "                \n",
    "                gt1,gt2,white_rating,black_rating,file_name = game_tensors\n",
    "                #print(np.array(gt1.shape),np.array([white_rating]).shape)\n",
    "                f = files[file_name]\n",
    "                if f.get(\"game_tensors\") is None:\n",
    "                    f.create_dataset(\"game_tensors\",shape=(CHUNKSIZE,40,136),maxshape=(None,40,136),chunks=True,compression='lzf')#,compression_opts=1)\n",
    "                    f.create_dataset(\"ratings\",shape=(CHUNKSIZE,1),chunks=True,maxshape=(None,1))#,compression='gzip',compression_opts=9)\n",
    "                    f[\"game_tensors\"][0] = gt1\n",
    "                    f[\"game_tensors\"][1] = gt2\n",
    "                    f[\"ratings\"][0] = np.array([white_rating])\n",
    "                    f[\"ratings\"][1] = np.array([black_rating])\n",
    "                    file_indexes[file_name] = 2\n",
    "                else: #file already exists\n",
    "                    #check if we need to resize the dataset\n",
    "                    if file_indexes[file_name]+1 >= f[\"game_tensors\"].shape[0]:\n",
    "                        print(\"enlarging chunk for file\",file_name)\n",
    "                    #+1 as we are writing 2 games at a time\n",
    "                        f[\"game_tensors\"].resize((f[\"game_tensors\"].shape[0] + CHUNKSIZE,40,136))\n",
    "                        f[\"ratings\"].resize((f[\"ratings\"].shape[0] + CHUNKSIZE,1))\n",
    "                    #write the new game\n",
    "                    f[\"game_tensors\"][file_indexes[file_name]] = gt1\n",
    "                    f[\"game_tensors\"][file_indexes[file_name]+1] = gt2\n",
    "                    f[\"ratings\"][file_indexes[file_name]] = np.array([white_rating])\n",
    "                    f[\"ratings\"][file_indexes[file_name]+1] = np.array([black_rating])\n",
    "                    file_indexes[file_name] += 2\n",
    "                game = line\n",
    "        else: #continue reading the game\n",
    "            game += line\n",
    "\n",
    "    for file_name in files:\n",
    "        f = files[file_name]\n",
    "        #reshape the datasets to remove the extra space\n",
    "        f[\"game_tensors\"].resize((file_indexes[f],40,136))\n",
    "        f[\"ratings\"].resize((file_indexes[f],1))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow processing of \"plain\" files or \"zst\" files passed in from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fn):\n",
    "    #if the filename ends in .pgn we will read it as a text file. If it ends in .zst we will read it as a compressed file using streaming.\n",
    "    if fn.endswith(\".pgn\"):\n",
    "        with open(fn,\"r\") as f:\n",
    "            write_to_hdf5(f)\n",
    "    elif fn.endswith(\".zst\"):\n",
    "        with open(fn,\"rb\") as f:\n",
    "            dctx = zstd.ZstdDecompressor()\n",
    "            with dctx.stream_reader(f) as reader:\n",
    "                text_stream = TextIOWrapper(reader, encoding='utf-8')\n",
    "                write_to_hdf5(text_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_file(\"data/all_data/lichess09.pgn.zst\")\n",
    "read_file(\"data/all_data/lichess05.pgn.zst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the hdf file up to some index and bins index values into 48 bins based on the rating. These bins are 600-650,650-700...\n",
    "def create_bins(f,start_index,end_index,bin_size,new_file): #N.B., f is a h5py file object\n",
    "    bins=[[]*48]\n",
    "    \n",
    "    ratings = f[\"ratings\"][start_index:end_index]\n",
    "    for r in range(len(ratings)):\n",
    "        bin=(ratings[r]-600)//50\n",
    "        bins[bin].append(r)\n",
    "    \n",
    "    with h5py.File(new_file,\"w\") as nf:\n",
    "        nf.create_dataset(\"game_tensors\",shape=(bin_size*48,NUM_MOVES,136))\n",
    "        nf.create_dataset(\"ratings\",shape=(bin_size*48,1))\n",
    "\n",
    "        #for each bin, randomly sample bin_size elements with replacement. If there are fewer than bin_size elements, first copy them all before sampling with replacement.\n",
    "\n",
    "        for i in range(48):\n",
    "             #copy the elements we have\n",
    "            c = 0\n",
    "            for b in bins[i]:\n",
    "                nf[\"game_tensors\"][i*bin_size+c] = f[\"game_tensors\"][b]\n",
    "                nf[\"ratings\"][i*bin_size+c] = f[\"ratings\"][b]\n",
    "                c += 1\n",
    "            #sample with replacement\n",
    "            for j in range(bin_size-c):\n",
    "                nf[\"game_tensors\"][i*bin_size+c+j] = f[\"game_tensors\"][np.random.choice(bins[i])]\n",
    "                nf[\"ratings\"][i*bin_size+c+j] = f[\"ratings\"][np.random.choice(bins[i])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, file, batch_size, start_index,end_index):\n",
    "        self.f = h5py.File(file,\"r\",rdcc_nbytes=5*10**8) #500MB cache\n",
    "        self.batch_size = batch_size\n",
    "        self.start_index = start_index\n",
    "        self.end_index = end_index\n",
    "        \n",
    "        self.current_index = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.end_index-self.start_index//self.batch_size\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #if we are not shuffling, we just return the next batch\n",
    "        if self.current_index + self.batch_size >= self.end_index:\n",
    "            x_batch = self.f[\"game_tensors\"][self.current_index:self.end_index]\n",
    "            y_batch = self.f[\"ratings\"][self.current_index:self.end_index]\n",
    "            x_batch2 = self.f[\"game_tensors\"][0:self.current_index+self.batch_size-self.end_index]\n",
    "            y_batch2 = self.f[\"ratings\"][0:self.current_index+self.batch_size-self.end_index]\n",
    "            \n",
    "            x_batch = np.concatenate((x_batch,x_batch2))\n",
    "            y_batch = np.concatenate((y_batch,y_batch2))\n",
    "            self.current_index = self.current_index+self.batch_size-self.end_index\n",
    "        else:\n",
    "            x_batch = self.f[\"game_tensors\"][self.current_index:self.current_index+self.batch_size]\n",
    "            y_batch = self.f[\"ratings\"][self.current_index:self.current_index+self.batch_size]\n",
    "            self.current_index += self.batch_size\n",
    "        \n",
    "        return x_batch,y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.current_index = 0\n",
    "        \n",
    "\n",
    "    def __del__(self):\n",
    "        self.f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b5/18y973ts67j9yzycz19jz1nr0000gn/T/ipykernel_6256/940927989.py:2: UserWarning: you are shuffling a 'Dataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(f[\"game_tensors\"])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[173], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblitz.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgame_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:4654\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.shuffle\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:4657\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.shuffle\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/h5py/_hl/dataset.py:781\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 781\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with h5py.File(\"blitz.hdf5\",\"r\") as f:\n",
    "    np.random.shuffle(f[\"game_tensors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
