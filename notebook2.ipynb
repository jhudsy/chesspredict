{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 09:07:39.259175: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "#from keras.layers import CategoryEncoding\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "import os,io\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import chess\n",
    "import chess.pgn\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "NUM_MOVES = 40 #number of moves to store in tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(game):\n",
    "\n",
    "    return int(game.headers['WhiteElo']),int(game.headers['BlackElo'])\n",
    "\n",
    "def rating_to_output(rating):\n",
    "    ret = np.zeros(48)\n",
    "    r = int((rating-600)/50)\n",
    "    if r>47:\n",
    "        r = 47\n",
    "    if r<0:\n",
    "        r = 0\n",
    "    ret[r] = 1\n",
    "    return ret\n",
    "\n",
    "def get_game_tensors(game_pgn,num_tensors):\n",
    "\n",
    "    gt = np.zeros((num_tensors,137))\n",
    "\n",
    "    moves = []\n",
    "    evals = []\n",
    "    clock = []\n",
    "\n",
    "    for m in game_pgn.mainline():\n",
    "        moves.append(m.san())\n",
    "        clock.append(m.clock())\n",
    "        if m.eval() is None: #should only happen on a mate\n",
    "            evals.append(None)\n",
    "        else:\n",
    "            evals.append(m.eval().white() if m.turn() == chess.WHITE else m.eval().black())\n",
    "\n",
    "    #let our t vector be a 1D array of 130 elements. The first 128 element represent the board before the move is made and after the move is made. The 129th element is 1 if it is white moved and -1 if it is black making the move. The 130th element is the move number.\n",
    "\n",
    "    board = chess.Board()\n",
    "\n",
    "    for m in range(0,min(num_tensors,len(moves)-1)):\n",
    "        t = np.zeros(137)\n",
    "\n",
    "        for i in range(64): #original board position\n",
    "            if board.piece_at(i) is not None:\n",
    "                                t[i] = board.piece_at(i).piece_type * (1 if board.piece_at(i).color == chess.WHITE else -1)\n",
    "\n",
    "        board.push_san(moves[m])\n",
    "        for i in range(64):\n",
    "            if board.piece_at(i) is not None:\n",
    "                t[i+64] = board.piece_at(i).piece_type * (1 if board.piece_at(i).color == chess.WHITE else -1)\n",
    "\n",
    "        #evals is either a number, or starts with a #. If it starts with a #, it is a mate in X moves\n",
    "\n",
    "        #handle the case of a mate\n",
    "        if evals[m] is None:\n",
    "            t[129] = 0\n",
    "            t[130] = 1\n",
    "        if evals[m+1] is None:\n",
    "            t[131] = 0\n",
    "            t[132] = 1\n",
    "\n",
    "        if evals[m] is not None and evals[m].is_mate():\n",
    "            t[129] = float(evals[m].mate())\n",
    "            t[130] = 1\n",
    "        elif evals[m] is not None:\n",
    "            t[129] = float(evals[m].score()/100)\n",
    "            t[130] = 0\n",
    "\n",
    "        if evals[m+1] is not None and evals[m+1].is_mate():\n",
    "            t[131] = float(evals[m+1].mate())\n",
    "            t[132] = 1\n",
    "        elif evals[m+1] is not None:\n",
    "            t[131] = float(evals[m+1].score()/100)\n",
    "            t[132] = 0\n",
    "\n",
    "        t[133] = -1 if board.turn == chess.WHITE else 1\n",
    "        t[134] = m #record the move number\n",
    "        t[135] = clock[m]\n",
    "        t[136] = clock[m+1]\n",
    "\n",
    "        gt[m] = t\n",
    "\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_game(game_file,start_pos):\n",
    "    #read from game_file line by line. Extract the part between [Event ...] and the next [Event ...]. Return the extracted string and the position in game_file of the start of the next game.\n",
    "\n",
    "    game = \"\"\n",
    "    pos = start_pos\n",
    "    #seek to the start_pos\n",
    "    game_file.seek(pos)\n",
    "    found_start = False\n",
    "    found_end = False\n",
    "    \n",
    "    while not found_start:\n",
    "        line = game_file.readline()\n",
    "        if line == \"\":\n",
    "            #print(\"NULL FOUND\")\n",
    "            return None,None\n",
    "        if line.startswith(\"[Event \"):\n",
    "            found_start = True\n",
    "            game += line\n",
    "    \n",
    "    while not found_end:\n",
    "        pos = game_file.tell()\n",
    "        line = game_file.readline()\n",
    "        if line.startswith(\"[Event \") or line == \"\":    \n",
    "            found_end = True\n",
    "        else:\n",
    "            game += line\n",
    "\n",
    "    return game,pos\n",
    "\n",
    "def check_game(string):\n",
    "    #checks if there is a string 'TimeControl \"600+0\"' in the game string, whether the string contains the string 'eval' and whether the string 'WhiteRatingDiff \"X\"' and 'BlackRatingDiff \"Y\"' are present and the absolute values of X and Y are less than 40.\n",
    "\n",
    "    #print(\"GAME STRING:\",string,\"END GAME STRING\")\n",
    "    if string == \"\":\n",
    "        return None\n",
    "\n",
    "    if 'TimeControl \"300+0\"' in string and 'eval' in string and 'WhiteRatingDiff' in string and 'BlackRatingDiff' in string:\n",
    "        white_diff = int(string.split('WhiteRatingDiff \"')[1].split('\"')[0])\n",
    "        black_diff = int(string.split('BlackRatingDiff \"')[1].split('\"')[0])\n",
    "        if abs(white_diff) < 40 and abs(black_diff) < 40:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(game_file,path,target_file):\n",
    "    count = 0\n",
    "    found_count = 0\n",
    "    X,y1,y2 = [],[],[]\n",
    "\n",
    "    with open(game_file) as f:\n",
    "\n",
    "        pos = 0\n",
    "        while True:\n",
    "            game,pos = extract_game(f,pos)\n",
    "            if game is None:\n",
    "                break\n",
    "            if check_game(game):\n",
    "                #print(\"Found game:\",game)\n",
    "                game = chess.pgn.read_game(io.StringIO(game))\n",
    "                gt = get_game_tensors(game,NUM_MOVES)\n",
    "                y1t = get_ratings(game)[0]\n",
    "                y2t = get_ratings(game)[1]\n",
    "\n",
    "                X.append(gt)\n",
    "                y1.append(y1t)\n",
    "                y2.append(y2t)\n",
    "                found_count += 1\n",
    "                if found_count % 1000 == 0:\n",
    "                    print(\"Found \" + str(found_count) + \" games\")\n",
    "                    np.savez_compressed(os.path.join(path,target_file + \"_X.npz\"),np.array(X))\n",
    "                    np.savez_compressed(os.path.join(path,target_file + \"_y1.npz\"),np.array(y1))\n",
    "                    np.savez_compressed(os.path.join(path,target_file + \"_y2.npz\"),np.array(y2))\n",
    "\n",
    "\n",
    "            count += 1\n",
    "            if count % 100000 == 0:\n",
    "                print(\"Read \" + str(count) + \" games\")\n",
    "\n",
    "    X = np.array(X)\n",
    "    y1 = np.array(y1)\n",
    "    y2 = np.array(y2)\n",
    "\n",
    "    #save the data to the target file\n",
    "    np.savez_compressed(os.path.join(path,target_file + \"_X.npz\"),X)\n",
    "    np.savez_compressed(os.path.join(path,target_file + \"_y1.npz\"),y1)\n",
    "    np.savez_compressed(os.path.join(path,target_file + \"_y2.npz\"),y2)\n",
    "\n",
    "def load_data(path,target_file):\n",
    "    X = np.load(os.path.join(path,target_file + \"_X.npz\"))[\"arr_0\"]\n",
    "    y1 = np.load(os.path.join(path,target_file + \"_y1.npz\"))[\"arr_0\"]\n",
    "    y2 = np.load(os.path.join(path,target_file + \"_y2.npz\"))[\"arr_0\"]\n",
    "\n",
    "    return X,y1,y2\n",
    "\n",
    "def simplify_data_no_eval(X):\n",
    "    #transforms the 134 element tensor into a 131 element tensor by removing elements 129-132 and replacing them with a single element that is 1 if white is moving and -1 if black is moving and a single element that is the move number\n",
    "    Xs = np.zeros((X.shape[0],X.shape[1],132))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            Xs[i][j][0:64] = X[i][j][0:64]\n",
    "            Xs[i][j][64:128] = X[i][j][64:128]\n",
    "            Xs[i][j][128] = X[i][j][133]\n",
    "            #element Xs[i][j][129] is the move number, i.e., j\n",
    "            Xs[i][j][129] = j\n",
    "            Xs[i][j][130] = X[i][j][135] #clock\n",
    "            Xs[i][j][131] = X[i][j][136] #clock\n",
    "\n",
    "    return Xs\n",
    "\n",
    "def simplify_data_eval_only(X):\n",
    "    #takes only elements 129-133 and adds move number\n",
    "    Xs = np.zeros((X.shape[0],X.shape[1],8))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            Xs[i][j][0] = X[i][j][129]\n",
    "            Xs[i][j][1] = X[i][j][130]\n",
    "            Xs[i][j][2] = X[i][j][131]\n",
    "            Xs[i][j][3] = X[i][j][132]\n",
    "            Xs[i][j][4] = X[i][j][133]\n",
    "            Xs[i][j][5] = j\n",
    "            Xs[i][j][6] = X[i][j][135] #clock\n",
    "            Xs[i][j][7] = X[i][j][136] #clock\n",
    "\n",
    "    return Xs\n",
    "\n",
    "#if the data doesn't exist, generate it\n",
    "if not os.path.exists(\"data/all_data/data_X.npz\"):\n",
    "    make_data(\"data/all_data/lichess.pgn\",\"data/all_data/\",\"data\")\n",
    "\n",
    "X,y1,y2 = load_data(\"data/all_data\",\"data\")\n",
    "\n",
    "#X = simplify_data_eval_only(X)\n",
    "#X = simplify_data_no_eval(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will take in our X,y1,y2 data and split it into bins of 50 rating points across y1 and y2.\n",
    "\n",
    "def bin_data(X,y1,y2):\n",
    "    bins = {}\n",
    "    for i in range(len(y1)):\n",
    "        bin1 = int(y1[i]/50)\n",
    "        bin2 = int(y2[i]/50)\n",
    "        if (bin1,bin2) not in bins:\n",
    "            bins[(bin1,bin2)] = []\n",
    "        \n",
    "        bins[(bin1,bin2)].append((X[i],y1[i],y2[i]))\n",
    "        \n",
    "    return bins\n",
    "\n",
    "def oversample(bins,num_samples):\n",
    "    #pick a total of num_samples samples from the bins by selecting a bin from bins at random and then selecting a sample from that bin at random\n",
    "    retX,retY1,retY2 = [],[],[]\n",
    "    for i in range(num_samples):\n",
    "        bin = random.choice(list(bins.keys()))\n",
    "        sample = random.choice(bins[bin])\n",
    "        retX.append(sample[0])\n",
    "        retY1.append(sample[1])\n",
    "        retY2.append(sample[2])\n",
    "\n",
    "    return np.array(retX),np.array(retY1),np.array(retY2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    #inputs = Input(shape=(NUM_MOVES, 132)) #if no eval is used\n",
    "    inputs = Input(shape=(NUM_MOVES, 137)) #full tensor\n",
    "    #inputs = Input(shape=(NUM_MOVES,8)) #if only the eval is used\n",
    "    \n",
    "    x = inputs\n",
    "\n",
    "    #prepare hyperparameter tuning\n",
    "\n",
    "    num_LSTM_layers = hp.Int('num_LSTM_layers',0,2)\n",
    "    num_LSTM_units=[]\n",
    "    for i in range(num_LSTM_layers+1):\n",
    "        num_LSTM_units.append(hp.Int('lstm'+str(i)+'_units',\n",
    "                                     min_value = 32,\n",
    "                                     max_value = 256,\n",
    "                                     step=16))\n",
    "        \n",
    "                                     \n",
    "    num_dense_layers = hp.Int('num_dense_layers',1,3)\n",
    "    num_dense_units = []\n",
    "    dense_activation = []\n",
    "\n",
    "    for i in range(num_dense_layers):\n",
    "        num_dense_units.append(hp.Int('dense'+str(i)+'_units',\n",
    "                                     min_value = 32,\n",
    "                                     max_value = 256,\n",
    "                                     step=16))\n",
    "        dense_activation.append(hp.Choice(\"dense\"+str(i)+\"_activation\",[\"relu\", \"selu\",\"leaky_relu\",\"tanh\"]))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-2])\n",
    "\n",
    "    #make the NN\n",
    "\n",
    "    for i in range(num_LSTM_layers):\n",
    "        x = LSTM(num_LSTM_units[i],return_sequences = True)(x)\n",
    "\n",
    "    #add a final LSTM layer that doesn't return sequences\n",
    "    x = LSTM(num_LSTM_units[-1])(x)\n",
    "    \n",
    "    for i in range(num_dense_layers):\n",
    "        x = Dense(num_dense_units[i],activation = dense_activation[i])(x)\n",
    "\n",
    "\n",
    "    output1 = Dense(1,activation='relu',name=\"WhiteElo\")(x)\n",
    "    output2 = Dense(1,activation='relu',name=\"BlackElo\")(x)\n",
    "\n",
    "    #Alternative: set outputs to be hot encoded between 48 values\n",
    "    #output1 = Dense(48,activation='softmax',name=\"WhiteElo\")(x)\n",
    "    #output2 = Dense(48,activation='softmax',name=\"BlackElo\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs,outputs=[output1,output2])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                    loss={'WhiteElo':'mae','BlackElo':'mae'},\n",
    "                    metrics={'WhiteElo':'mae','BlackElo':'mae'})\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=100,\n",
    "                     factor=3)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "save = tf.keras.callbacks.ModelCheckpoint('model.keras', save_best_only=True,mode='auto',monitor='val_loss')\n",
    "\n",
    "tuner.search(X,(y1,y2),epochs=100,validation_split=0.2,callbacks=[stop_early])\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(best_hps.values)\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "history = model.fit(X,(y1,y2),epochs=100,validation_split=0.2,callbacks=[stop_early,save])\n",
    "model.save('model3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 39ms/step - loss: 952.1003 - mae: 952.1003 - val_loss: 330.2997 - val_mae: 330.2997\n",
      "Epoch 2/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 37ms/step - loss: 315.1604 - mae: 315.1604 - val_loss: 260.5688 - val_mae: 260.5688\n",
      "Epoch 3/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 37ms/step - loss: 251.3730 - mae: 251.3730 - val_loss: 235.5315 - val_mae: 235.5315\n",
      "Epoch 4/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 38ms/step - loss: 222.9726 - mae: 222.9726 - val_loss: 222.7666 - val_mae: 222.7666\n",
      "Epoch 5/100\n",
      "\u001b[1m2896/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 204.7387 - mae: 204.7387"
     ]
    }
   ],
   "source": [
    "#bins = bin_data(X,y1,y2)\n",
    "#print(\"bins made\")\n",
    "#OX,Oy1,Oy2 = oversample(bins,len(X))\n",
    "\n",
    "inputs = Input(shape=(NUM_MOVES, 137)) #full tensor\n",
    "x = LSTM(80,return_sequences = True)(inputs)\n",
    "x = LSTM(32)(x)\n",
    "x = Dense(80,activation='relu')(x)\n",
    "\n",
    "\n",
    "output1 = Dense(1,activation='relu',name=\"WhiteElo\")(x)\n",
    "output2 = Dense(1,activation='relu',name=\"BlackElo\")(x)\n",
    "\n",
    "modelW = keras.Model(inputs=inputs,outputs=[output1])\n",
    "\n",
    "modelW.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss={'WhiteElo':'mae'},\n",
    "                    metrics={'WhiteElo':'mae'})\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "save = tf.keras.callbacks.ModelCheckpoint('modelO1W.keras', save_best_only=True,mode='auto',monitor='val_loss')\n",
    "\n",
    "modelW.fit(OX,Oy1,epochs=100,validation_split=0.2,callbacks=[stop_early,save])\n",
    "\n",
    "modelW.save('modelO1W.keras')\n",
    "\n",
    "\n",
    "modelB = keras.Model(inputs=inputs,outputs=[output2])\n",
    "\n",
    "modelB.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss={'BlackElo':'mae'},\n",
    "                    metrics={'BlackElo':'mae'})\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "save = tf.keras.callbacks.ModelCheckpoint('modelO1B.keras', save_best_only=True,mode='auto',monitor='val_loss')\n",
    "\n",
    "modelB.fit(OX,Oy2,epochs=100,validation_split=0.2,callbacks=[stop_early,save])\n",
    "\n",
    "modelB.save('modelO1B.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(NUM_MOVES, 137)) #full tensor\n",
    "x = LSTM(80,return_sequences = True)(inputs)\n",
    "x = LSTM(34)(x)\n",
    "x = Dense(82,activation='relu')(x)\n",
    "\n",
    "output1 = Dense(1,activation='relu',name=\"WhiteElo\")(x)\n",
    "output2 = Dense(1,activation='relu',name=\"BlackElo\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs,outputs=[output1,output2])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss={'WhiteElo':'mae','BlackElo':'mae'},\n",
    "                    metrics={'WhiteElo':'mae','BlackElo':'mae'})\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "save = tf.keras.callbacks.ModelCheckpoint('model2.keras', save_best_only=True,mode='auto',monitor='val_loss')\n",
    "\n",
    "model.fit(X,(y1,y2),epochs=100,validation_split=0.2,callbacks=[stop_early,save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 137)\n",
      "[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1929.3486]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1925.526]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "def analyse_game(file,model):\n",
    "    with open(file) as f:\n",
    "        game,pos = extract_game(f,0)\n",
    "        game = chess.pgn.read_game(io.StringIO(game))\n",
    "        gt = get_game_tensors(game,NUM_MOVES)\n",
    "\n",
    "        print(gt.shape)\n",
    "        #gt = simplify_data_no_eval(gt)\n",
    "        #gt = simplify_data_eval_only(gt)\n",
    "        return model(np.array([gt]),training=False)\n",
    "    \n",
    "model = keras.models.load_model('model2.keras')\n",
    "\n",
    "print(analyse_game(\"data/all_data/2200.pgn\",model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bins made\n",
      "Epoch 1/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 45ms/step - BlackElo_loss: 1062.6196 - BlackElo_mae: 1062.6198 - WhiteElo_loss: 1676.3533 - WhiteElo_mae: 1676.3533 - loss: 2738.9702 - val_BlackElo_loss: 400.4082 - val_BlackElo_mae: 400.3332 - val_WhiteElo_loss: 1677.0237 - val_WhiteElo_mae: 1676.9172 - val_loss: 2077.2517\n",
      "Epoch 2/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 44ms/step - BlackElo_loss: 390.8853 - BlackElo_mae: 390.8853 - WhiteElo_loss: 1675.2872 - WhiteElo_mae: 1675.2872 - loss: 2066.1704 - val_BlackElo_loss: 346.6739 - val_BlackElo_mae: 346.5921 - val_WhiteElo_loss: 1677.0237 - val_WhiteElo_mae: 1676.9172 - val_loss: 2023.5093\n",
      "Epoch 3/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 40ms/step - BlackElo_loss: 322.4926 - BlackElo_mae: 322.4926 - WhiteElo_loss: 1676.0620 - WhiteElo_mae: 1676.0620 - loss: 1998.5541 - val_BlackElo_loss: 276.2462 - val_BlackElo_mae: 276.2498 - val_WhiteElo_loss: 1677.0237 - val_WhiteElo_mae: 1676.9172 - val_loss: 1953.1663\n",
      "Epoch 4/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 52ms/step - BlackElo_loss: 276.5823 - BlackElo_mae: 276.5823 - WhiteElo_loss: 1676.0065 - WhiteElo_mae: 1676.0065 - loss: 1952.5896 - val_BlackElo_loss: 247.3618 - val_BlackElo_mae: 247.3427 - val_WhiteElo_loss: 1677.0237 - val_WhiteElo_mae: 1676.9172 - val_loss: 1924.2615\n",
      "Epoch 5/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 42ms/step - BlackElo_loss: 246.1272 - BlackElo_mae: 246.1272 - WhiteElo_loss: 1675.4067 - WhiteElo_mae: 1675.4067 - loss: 1921.5333 - val_BlackElo_loss: 233.9295 - val_BlackElo_mae: 233.9819 - val_WhiteElo_loss: 1677.0237 - val_WhiteElo_mae: 1676.9172 - val_loss: 1910.8984\n",
      "Epoch 6/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 49ms/step - BlackElo_loss: 222.0400 - BlackElo_mae: 222.0400 - WhiteElo_loss: 1676.0508 - WhiteElo_mae: 1676.0508 - loss: 1898.0919 - val_BlackElo_loss: 213.7641 - val_BlackElo_mae: 213.7847 - val_WhiteElo_loss: 1677.0237 - val_WhiteElo_mae: 1676.9172 - val_loss: 1890.7019\n",
      "Epoch 7/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 48ms/step - BlackElo_loss: 207.6377 - BlackElo_mae: 207.6377 - WhiteElo_loss: 1676.6219 - WhiteElo_mae: 1676.6219 - loss: 1884.2598 - val_BlackElo_loss: 210.3440 - val_BlackElo_mae: 210.4416 - val_WhiteElo_loss: 1677.0237 - val_WhiteElo_mae: 1676.9172 - val_loss: 1887.3588\n",
      "Epoch 8/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 46ms/step - BlackElo_loss: 189.8484 - BlackElo_mae: 189.8484 - WhiteElo_loss: 1675.1523 - WhiteElo_mae: 1675.1523 - loss: 1865.0000 - val_BlackElo_loss: 190.0764 - val_BlackElo_mae: 190.1214 - val_WhiteElo_loss: 1677.0237 - val_WhiteElo_mae: 1676.9172 - val_loss: 1867.0400\n",
      "Epoch 9/100\n",
      "\u001b[1m2897/2897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 46ms/step - BlackElo_loss: 177.5477 - BlackElo_mae: 177.5477 - WhiteElo_loss: 1673.9243 - WhiteElo_mae: 1673.9243 - loss: 1851.4712 - val_BlackElo_loss: 173.7378 - val_BlackElo_mae: 173.7287 - val_WhiteElo_loss: 1677.0237 - val_WhiteElo_mae: 1676.9172 - val_loss: 1850.6475\n",
      "Epoch 10/100\n",
      "\u001b[1m 484/2897\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 45ms/step - BlackElo_loss: 168.2447 - BlackElo_mae: 168.2447 - WhiteElo_loss: 1672.5399 - WhiteElo_mae: 1672.5399 - loss: 1840.7845"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m OX,Oy1,Oy2 \u001b[38;5;241m=\u001b[39m oversample(bins,\u001b[38;5;28mlen\u001b[39m(X))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#model.fit(X,(y1,y2),epochs=100,validation_split=0.2,callbacks=[stop_early,save])\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOy1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mOy2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstop_early\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "inputs = Input(shape=(NUM_MOVES, 137)) #full tensor\n",
    "\n",
    "#make a dense layer for each of the NUM_MOVES elements. The output of each dense layer is a 1D tensor of 137 elements. Each of these tensors is then concatenated to form a 2D tensor of 137xNUM_MOVES elements. This tensor is then fed into an LSTM layer.\n",
    "\n",
    "x = TimeDistributed(Dense(130,activation = 'leaky_relu'))(inputs)\n",
    "\n",
    "x = LSTM(80,return_sequences = True)(x)\n",
    "x = LSTM(32)(x)\n",
    "x = Dense(60,activation='relu')(x)\n",
    "\n",
    "output1 = Dense(1,activation='relu',name=\"WhiteElo\")(x)\n",
    "output2 = Dense(1,activation='relu',name=\"BlackElo\")(x)\n",
    "\n",
    "#model = keras.Model(inputs=inputs,outputs=[output1,output2])\n",
    "\n",
    "#model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "#                    loss={'WhiteElo':'mae','BlackElo':'mae'},\n",
    "#                    metrics={'WhiteElo':'mae','BlackElo':'mae'})\n",
    "\n",
    "modelW = keras.Model(inputs=inputs,outputs=[output1])\n",
    "\n",
    "modelW.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss={'WhiteElo':'mae'},\n",
    "                    metrics={'WhiteElo':'mae'})\n",
    "\n",
    "\n",
    "modelB = keras.Model(inputs=inputs,outputs=[output2])\n",
    "\n",
    "modelB.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss={'BlackElo':'mae'},\n",
    "                    metrics={'BlackElo':'mae'})\n",
    "\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "save = tf.keras.callbacks.ModelCheckpoint('modelOTW.keras', save_best_only=True,mode='auto',monitor='val_loss')\n",
    "\n",
    "bins = bin_data(X,y1,y2)\n",
    "print(\"bins made\")\n",
    "OX,Oy1,Oy2 = oversample(bins,len(X))\n",
    "\n",
    "\n",
    "#model.fit(X,(y1,y2),epochs=100,validation_split=0.2,callbacks=[stop_early,save])\n",
    "modelW.fit(OX,Oy1,epochs=100,validation_split=0.2,callbacks=[stop_early,save])\n",
    "modelB.fit(OX,Oy1,epochs=100,validation_split=0.2,callbacks=[stop_early,save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0\n",
      "count  115872.000000\n",
      "mean     1675.814053\n",
      "std       469.983165\n",
      "min       772.000000\n",
      "25%      1291.000000\n",
      "50%      1677.000000\n",
      "75%      2060.000000\n",
      "max      2686.000000\n",
      "                   0\n",
      "count  115872.000000\n",
      "mean     1592.375000\n",
      "std       291.191491\n",
      "min       772.000000\n",
      "25%      1387.000000\n",
      "50%      1599.000000\n",
      "75%      1799.000000\n",
      "max      2686.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1759., 1323., 1513.,  958., 1897., 2411., 1896., 2752., 2696.,\n",
       "        2576., 2460., 2743., 2579., 2477., 2974., 2663., 3224., 2555.,\n",
       "        2761., 2925., 2477., 3155., 3334., 2680., 3160., 2969., 2869.,\n",
       "        2851., 2818., 3023., 2737., 2936., 3030., 2885., 2563., 2380.,\n",
       "        2584., 3051., 3043., 1990., 2378., 1750., 2466., 1407., 1261.,\n",
       "        1092., 1230.,  118.,  383.,  110.]),\n",
       " array([ 772.  ,  810.28,  848.56,  886.84,  925.12,  963.4 , 1001.68,\n",
       "        1039.96, 1078.24, 1116.52, 1154.8 , 1193.08, 1231.36, 1269.64,\n",
       "        1307.92, 1346.2 , 1384.48, 1422.76, 1461.04, 1499.32, 1537.6 ,\n",
       "        1575.88, 1614.16, 1652.44, 1690.72, 1729.  , 1767.28, 1805.56,\n",
       "        1843.84, 1882.12, 1920.4 , 1958.68, 1996.96, 2035.24, 2073.52,\n",
       "        2111.8 , 2150.08, 2188.36, 2226.64, 2264.92, 2303.2 , 2341.48,\n",
       "        2379.76, 2418.04, 2456.32, 2494.6 , 2532.88, 2571.16, 2609.44,\n",
       "        2647.72, 2686.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(Oy1)\n",
    "print(df.describe())\n",
    "\n",
    "df = pd.DataFrame(y1)\n",
    "print(df.describe())\n",
    "\n",
    "#plot the distribution of the ratings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(Oy1,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1950 is out of bounds for axis 1 with size 48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/keras/src/utils/numerical_utils.py:99\u001b[0m, in \u001b[0;36mto_categorical\u001b[0;34m(x, num_classes)\u001b[0m\n\u001b[1;32m     97\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     98\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size, num_classes))\n\u001b[0;32m---> 99\u001b[0m \u001b[43mcategorical\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    100\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m input_shape \u001b[38;5;241m+\u001b[39m (num_classes,)\n\u001b[1;32m    101\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(categorical, output_shape)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1950 is out of bounds for axis 1 with size 48"
     ]
    }
   ],
   "source": [
    "len(tf.keras.utils.to_categorical(y1,num_classes=48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115872,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
