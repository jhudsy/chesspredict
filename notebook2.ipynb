{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-01 16:18:56.558229: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "#from keras.layers import CategoryEncoding\n",
    "import keras_tuner as kt\n",
    "\n",
    "import os,io\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import chess\n",
    "import chess.pgn\n",
    "from chess.engine import PovScore, Mate, Cp\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "NUM_MOVES = 40 #number of moves to store in tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(game):\n",
    "\n",
    "    return int(game.headers['WhiteElo']),int(game.headers['BlackElo'])\n",
    "\n",
    "def rating_to_output(rating):\n",
    "    ret = np.zeros(48)\n",
    "    r = int((rating-600)/50)\n",
    "    if r>47:\n",
    "        r = 47\n",
    "    if r<0:\n",
    "        r = 0\n",
    "    ret[r] = 1\n",
    "    return ret\n",
    "\n",
    "def make_game_tensor(game,num_moves):\n",
    "  #print(game)\n",
    "  gt1 = np.zeros((num_moves,136))\n",
    "  gt2 = np.zeros((num_moves,136))\n",
    "  #we will make two game tensors from a game, one for each player. \n",
    "  #The tensor will be a 136 element tensor. The first 64 elements will be the board state, the next 64 will be the board state after the move. Element 129\n",
    "  # is the move number. Element 130 is the time on the clock at the start of the move and element 131 is the time on the clock after the move. Element 132 is the time on the clock of the opponent.\n",
    "  #Element 133 is the evaluation of the position before the move and 134 is the evaluation of the position after the move. Element 135 is a 1 if the evaluation before the move is a mate in ... and 0 otherwise while element 136 is a 1 if the evaluation after the move is a mate in ... and 0 otherwise.\n",
    "\n",
    "  #The board state itself is a 64 element tensor with 0 for empty spaces, 1...6 for the current color's pieces and 7...12 for the opponent's pieces. \n",
    "  board = game.board()\n",
    "  m = None #current move\n",
    "  white_time = 300\n",
    "  black_time = 300\n",
    "\n",
    "  move_number = 0\n",
    "\n",
    "  current_eval = PovScore(Cp(0), chess.WHITE)\n",
    "  current_move_color = chess.WHITE #start with white\n",
    "\n",
    "  while True:\n",
    "  \n",
    "    t = np.zeros(136)\n",
    "\n",
    "    for i in range(64):\n",
    "        if board.piece_at(i)==None:\n",
    "          t[i] = 0\n",
    "        elif board.piece_at(i).color == current_move_color:\n",
    "           t[i] = board.piece_at(i).piece_type\n",
    "        else:\n",
    "           t[i] = board.piece_at(i).piece_type+7\n",
    "      \n",
    "    #get the evaluation, time etc.\n",
    "\n",
    "    t[128] = move_number//2 #move number\n",
    "\n",
    "    t[129] = white_time if current_move_color == chess.WHITE else black_time\n",
    "  \n",
    "    t[131] = black_time if current_move_color == chess.WHITE else white_time\n",
    "  \n",
    "    if current_eval == None:\n",
    "      t[135] = 1\n",
    "      t[134] = 0\n",
    "    elif current_eval.pov(current_move_color).is_mate():\n",
    "      t[133] = 1\n",
    "      t[132] = current_eval.pov(current_move_color).mate()\n",
    "    else:\n",
    "      t[133] = 0\n",
    "      t[132] = current_eval.pov(current_move_color).score()\n",
    "  \n",
    "    if move_number == 0:\n",
    "       m = game.next()\n",
    "    else:\n",
    "      m = m.next()\n",
    "    if m == None:\n",
    "      break\n",
    "\n",
    "    if current_move_color == chess.WHITE:\n",
    "      white_time = m.clock()\n",
    "    else:\n",
    "      black_time = m.clock()\n",
    "      \n",
    "    current_eval = m.eval()\n",
    "    board = m.board()\n",
    "\n",
    "    for i in range(64):\n",
    "        if board.piece_at(i)==None:\n",
    "          t[i+64] = 0\n",
    "        elif board.piece_at(i).color == current_move_color:\n",
    "          t[i+64] = board.piece_at(i).piece_type\n",
    "        else:\n",
    "          t[i+64] = board.piece_at(i).piece_type+7\n",
    "  \n",
    "    t[130] = white_time if current_move_color == chess.WHITE else black_time\n",
    "\n",
    "    if current_eval == None:\n",
    "      t[135] = 1\n",
    "      t[134] = 0\n",
    "    elif current_eval.pov(current_move_color).is_mate():\n",
    "      t[135] = 1\n",
    "      t[134] = current_eval.pov(current_move_color).mate()\n",
    "    else:\n",
    "      t[135] = 0\n",
    "      t[134] = current_eval.pov(current_move_color).score()\n",
    "\n",
    "    if current_move_color == chess.WHITE:\n",
    "      gt1[move_number//2] = t\n",
    "    else:\n",
    "      gt2[move_number//2] = t\n",
    "\n",
    "    current_move_color = not current_move_color\n",
    "\n",
    "    move_number+=1\n",
    "\n",
    "    if move_number == num_moves*2:\n",
    "      break\n",
    "\n",
    "  return np.array(gt1),np.array(gt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_game(string):\n",
    "    #checks if there is a string 'TimeControl \"600+0\"' in the game string, whether the string contains the string 'eval' and whether the string 'WhiteRatingDiff \"X\"' and 'BlackRatingDiff \"Y\"' are present and the absolute values of X and Y are less than 40.\n",
    "\n",
    "    #print(\"GAME STRING:\",string,\"END GAME STRING\")\n",
    "    if string == \"\":\n",
    "        return None\n",
    "\n",
    "    if 'TimeControl \"300+0\"' in string and 'eval' in string and 'WhiteRatingDiff' in string and 'BlackRatingDiff' in string:\n",
    "        white_diff = int(string.split('WhiteRatingDiff \"')[1].split('\"')[0])\n",
    "        black_diff = int(string.split('BlackRatingDiff \"')[1].split('\"')[0])\n",
    "        if abs(white_diff) < 40 and abs(black_diff) < 40:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def extract_games(source_file,target_file): \n",
    "    tf = open(target_file,'w')\n",
    "    \n",
    "    game = \"\"\n",
    "\n",
    "    with open(source_file) as f:\n",
    "        for line in f.readline():\n",
    "            if line.startswith(\"[Event \") and game==\"\":\n",
    "                game=line\n",
    "            elif line.startswith(\"[Event \"):\n",
    "                if check_game(game):\n",
    "                    tf.write(game)\n",
    "                game = line\n",
    "            else:\n",
    "                game+=line\n",
    "\n",
    "def extract_games_stdin(target_file): \n",
    "    tf = open(target_file,'w')\n",
    "    \n",
    "    game = \"\"\n",
    "\n",
    "    for line in sys.stdin:\n",
    "        if line.startswith(\"[Event \") and game==\"\":\n",
    "            game=line\n",
    "        elif line.startswith(\"[Event \"):\n",
    "            if check_game(game):\n",
    "                tf.write(game)\n",
    "            game = line\n",
    "        else:\n",
    "            game+=line\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(game_file,path,target_file): #assumes that the game file is a pgn file with games that have the correct time control, evals and rating differences, see check_game function\n",
    "    found_count = 0\n",
    "    X,y, = [], []\n",
    "\n",
    "    with open(game_file) as f:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game == None:\n",
    "                break\n",
    "            if game.headers['Termination'] == \"Abandoned\" or game.headers['Termination'] == \"Rules infraction\" or len(list(game.mainline_moves())) < 15:\n",
    "                continue\n",
    "            y1,y2 = get_ratings(game)\n",
    "            gt1,gt2 = make_game_tensor(game,num_moves=NUM_MOVES)\n",
    "            X.append(gt1)\n",
    "            X.append(gt2)\n",
    "            y.append(y1)\n",
    "            y.append(y2)\n",
    "            found_count += 1\n",
    "            if found_count % 1000 == 0:\n",
    "                print(\"Found \" + str(found_count) + \" games\")\n",
    "                #np.savez_compressed(os.path.join(path,target_file + \"_X.npz\"),np.array(X))\n",
    "                #np.savez_compressed(os.path.join(path,target_file + \"_y.npz\"),np.array(y))\n",
    "                \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    #save the data to the target file\n",
    "    np.savez_compressed(os.path.join(path,target_file + \"_X.npz\"),X)\n",
    "    np.savez_compressed(os.path.join(path,target_file + \"_y.npz\"),y)\n",
    "\n",
    "def load_data(path,target_file):\n",
    "    X = np.load(os.path.join(path,target_file + \"_X.npz\"))[\"arr_0\"]\n",
    "    y = np.load(os.path.join(path,target_file + \"_y.npz\"))[\"arr_0\"]\n",
    "    \n",
    "\n",
    "    return X,y\n",
    "\n",
    "\n",
    "#if the data doesn't exist, generate it\n",
    "if not os.path.exists(\"data/all_data/data_X.npz\"):\n",
    "    make_data(\"data/all_data/extracted_games05.pgn\",\"data/all_data/\",\"data\")\n",
    "\n",
    "X,y = load_data(\"data/all_data\",\"data\")\n",
    "\n",
    "#X = simplify_data_eval_only(X)\n",
    "#X = simplify_data_no_eval(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bindata(X,y):\n",
    "    bins = {}\n",
    "    for i in range(len(y)):\n",
    "        bin = int(y[i]/50)\n",
    "        if bin not in bins:\n",
    "            bins[bin] = []\n",
    "        \n",
    "        bins[bin].append((X[i],y[i]))\n",
    "        \n",
    "    return bins\n",
    "\n",
    "def oversample(bins,num_samples):\n",
    "    #pick a total of num_samples samples from the bins by selecting a bin from bins at random and then selecting a sample from that bin at random\n",
    "    retX,retY = [],[]\n",
    "    for i in range(num_samples):\n",
    "        bin = random.choice(list(bins.keys()))\n",
    "        sample = random.choice(bins[bin])\n",
    "        retX.append(sample[0])\n",
    "        retY.append(sample[1])\n",
    "\n",
    "    return np.array(retX),np.array(retY)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    #inputs = Input(shape=(NUM_MOVES, 132)) #if no eval is used\n",
    "    inputs = Input(shape=(NUM_MOVES, 136)) #full tensor\n",
    "    #inputs = Input(shape=(NUM_MOVES,8)) #if only the eval is used\n",
    "    \n",
    "    x = inputs\n",
    "\n",
    "    #prepare hyperparameter tuning\n",
    "\n",
    "    num_LSTM_layers = hp.Int('num_LSTM_layers',0,2)\n",
    "    num_LSTM_units=[]\n",
    "    for i in range(num_LSTM_layers+1):\n",
    "        num_LSTM_units.append(hp.Int('lstm'+str(i)+'_units',\n",
    "                                     min_value = 32,\n",
    "                                     max_value = 64,\n",
    "                                     step=16))\n",
    "        \n",
    "                                     \n",
    "    num_dense_layers = hp.Int('num_dense_layers',1,3)\n",
    "    num_dense_units = []\n",
    "    dense_activation = []\n",
    "\n",
    "    for i in range(num_dense_layers):\n",
    "        num_dense_units.append(hp.Int('dense'+str(i)+'_units',\n",
    "                                     min_value = 32,\n",
    "                                     max_value = 128,\n",
    "                                     step=16))\n",
    "        dense_activation.append(hp.Choice(\"dense\"+str(i)+\"_activation\",[\"relu\", \"leaky_relu\",\"tanh\"]))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-2])\n",
    "\n",
    "    #make the NN\n",
    "\n",
    "    for i in range(num_LSTM_layers):\n",
    "        x = LSTM(num_LSTM_units[i],return_sequences = True)(x)\n",
    "\n",
    "    #add a final LSTM layer that doesn't return sequences\n",
    "    x = LSTM(num_LSTM_units[-1])(x)\n",
    "    \n",
    "    for i in range(num_dense_layers):\n",
    "        x = Dense(num_dense_units[i],activation = dense_activation[i])(x)\n",
    "\n",
    "\n",
    "    output = Dense(1,activation='relu',name=\"Elo\")(x)\n",
    "    \n",
    "\n",
    "    #Alternative: set outputs to be hot encoded between 48 values\n",
    "    #output1 = Dense(48,activation='softmax',name=\"WhiteElo\")(x)\n",
    "    #output2 = Dense(48,activation='softmax',name=\"BlackElo\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs,outputs=[output])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                    loss={'Elo':'mae'},\n",
    "                    metrics={'Elo':'mae'})\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 09m 30s]\n",
      "val_loss: 248.96511840820312\n",
      "\n",
      "Best val_loss So Far: 248.96511840820312\n",
      "Total elapsed time: 00h 18m 05s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1                 |2                 |num_LSTM_layers\n",
      "32                |48                |lstm0_units\n",
      "1                 |1                 |num_dense_layers\n",
      "112               |32                |dense0_units\n",
      "leaky_relu        |leaky_relu        |dense0_activation\n",
      "0.001             |0.01              |learning_rate\n",
      "64                |32                |lstm1_units\n",
      "80                |32                |dense1_units\n",
      "leaky_relu        |relu              |dense1_activation\n",
      "48                |32                |lstm2_units\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "4                 |4                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 571.5119 - mae: 571.5119"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=100,\n",
    "                     factor=3)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "save = tf.keras.callbacks.ModelCheckpoint('modelCP.keras', save_best_only=True,mode='auto',monitor='val_loss')\n",
    "\n",
    "#tuner.search(X,y,epochs=100,validation_split=0.2,callbacks=[stop_early])\n",
    "tuner.search(OX,Oy,epochs=100,validation_data=(X_val,y_val),callbacks=[stop_early])\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(best_hps.values)\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "#history = model.fit(X,y,epochs=100,validation_split=0.2,callbacks=[stop_early,save])\n",
    "model.save('modelHB.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bins made\n"
     ]
    }
   ],
   "source": [
    "#select 20% of the data to be used for validation\n",
    "\n",
    "split = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "\n",
    "X_val = X[split:]\n",
    "y_val = y[split:]\n",
    "\n",
    "bins = bindata(X_train,y_train)\n",
    "print(\"bins made\")\n",
    "OX,Oy = oversample(bins,len(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 31ms/step - loss: 649.3950 - mae: 649.3950 - val_loss: 284.8401 - val_mae: 284.8401\n",
      "Epoch 2/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 28ms/step - loss: 213.3430 - mae: 213.3430 - val_loss: 246.7147 - val_mae: 246.7147\n",
      "Epoch 3/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 28ms/step - loss: 200.5090 - mae: 200.5090 - val_loss: 232.7653 - val_mae: 232.7653\n",
      "Epoch 4/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 29ms/step - loss: 193.0782 - mae: 193.0782 - val_loss: 226.0233 - val_mae: 226.0233\n",
      "Epoch 5/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 29ms/step - loss: 186.9468 - mae: 186.9468 - val_loss: 216.0979 - val_mae: 216.0979\n",
      "Epoch 6/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 31ms/step - loss: 183.4679 - mae: 183.4679 - val_loss: 241.0153 - val_mae: 241.0153\n",
      "Epoch 7/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 32ms/step - loss: 179.6632 - mae: 179.6632 - val_loss: 216.8736 - val_mae: 216.8736\n",
      "Epoch 8/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 29ms/step - loss: 176.1404 - mae: 176.1404 - val_loss: 209.4211 - val_mae: 209.4211\n",
      "Epoch 9/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 34ms/step - loss: 172.9318 - mae: 172.9318 - val_loss: 223.1236 - val_mae: 223.1236\n",
      "Epoch 10/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 33ms/step - loss: 171.5529 - mae: 171.5529 - val_loss: 226.8889 - val_mae: 226.8889\n",
      "Epoch 11/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 29ms/step - loss: 169.7736 - mae: 169.7736 - val_loss: 229.1540 - val_mae: 229.1540\n",
      "Epoch 12/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 35ms/step - loss: 168.0284 - mae: 168.0284 - val_loss: 218.0567 - val_mae: 218.0567\n",
      "Epoch 13/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 34ms/step - loss: 166.7442 - mae: 166.7442 - val_loss: 226.0914 - val_mae: 226.0914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1608eea80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(shape=(NUM_MOVES, 136)) #full tensor\n",
    "x = LSTM(40,return_sequences = True)(inputs)\n",
    "x = LSTM(32)(x)\n",
    "x = Dense(80,activation='relu')(x)\n",
    "\n",
    "output1 = Dense(1,activation='relu',name=\"Elo\")(x)\n",
    "\n",
    "\n",
    "model = keras.Model(inputs=inputs,outputs=[output1])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss={'Elo':'mae'},\n",
    "                    metrics={'Elo':'mae'})\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "save = tf.keras.callbacks.ModelCheckpoint('modelO1.keras', save_best_only=True,mode='auto',monitor='val_loss')\n",
    "\n",
    "model.fit(OX,Oy,epochs=100,shuffle=True,validation_data=(X_val,y_val),callbacks=[stop_early,save])\n",
    "\n",
    "#model.fit(X,y,epochs=100,shuffle=True,validation_split=0.2,callbacks=[stop_early,save])\n",
    "\n",
    "#modelB.save('modelO1B.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 39ms/step - loss: 782.0889 - mae: 782.0889 - val_loss: 248.1543 - val_mae: 248.1543\n",
      "Epoch 2/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 35ms/step - loss: 235.4637 - mae: 235.4637 - val_loss: 269.3246 - val_mae: 269.3246\n",
      "Epoch 3/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 31ms/step - loss: 211.0840 - mae: 211.0840 - val_loss: 250.6162 - val_mae: 250.6162\n",
      "Epoch 4/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 31ms/step - loss: 201.2691 - mae: 201.2691 - val_loss: 224.1663 - val_mae: 224.1663\n",
      "Epoch 5/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 31ms/step - loss: 194.2975 - mae: 194.2975 - val_loss: 218.3687 - val_mae: 218.3687\n",
      "Epoch 6/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 31ms/step - loss: 188.6383 - mae: 188.6383 - val_loss: 220.7258 - val_mae: 220.7258\n",
      "Epoch 7/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 32ms/step - loss: 184.2579 - mae: 184.2579 - val_loss: 224.6676 - val_mae: 224.6676\n",
      "Epoch 8/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 32ms/step - loss: 180.9700 - mae: 180.9700 - val_loss: 205.4695 - val_mae: 205.4695\n",
      "Epoch 9/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 31ms/step - loss: 179.3856 - mae: 179.3856 - val_loss: 216.0677 - val_mae: 216.0677\n",
      "Epoch 10/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 32ms/step - loss: 176.3005 - mae: 176.3005 - val_loss: 224.8666 - val_mae: 224.8666\n",
      "Epoch 11/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 36ms/step - loss: 173.3592 - mae: 173.3592 - val_loss: 225.8448 - val_mae: 225.8448\n",
      "Epoch 12/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 34ms/step - loss: 172.2532 - mae: 172.2532 - val_loss: 216.4941 - val_mae: 216.4941\n",
      "Epoch 13/100\n",
      "\u001b[1m7130/7130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 31ms/step - loss: 169.3501 - mae: 169.3501 - val_loss: 219.5877 - val_mae: 219.5877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16363a540>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "inputs = Input(shape=(NUM_MOVES, 136)) #full tensor\n",
    "\n",
    "#make a dense layer for each of the NUM_MOVES elements. The output of each dense layer is a 1D tensor of 137 elements. Each of these tensors is then concatenated to form a 2D tensor of 137xNUM_MOVES elements. This tensor is then fed into an LSTM layer.\n",
    "\n",
    "x = TimeDistributed(Dense(80,activation = 'relu'))(inputs)\n",
    "\n",
    "x = LSTM(40,return_sequences = True)(x)\n",
    "x = LSTM(32)(x)\n",
    "x = Dense(60,activation='relu')(x)\n",
    "\n",
    "output = Dense(1,activation='relu',name=\"Elo\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs,outputs=[output])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss={'Elo':'mae'},\n",
    "                    metrics={'Elo':'mae'})\n",
    "\n",
    "\n",
    "#select 20% of the data to be used for validation\n",
    "\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "save = tf.keras.callbacks.ModelCheckpoint('modelOT.keras', save_best_only=True,mode='auto',monitor='val_loss')\n",
    "\n",
    "#model.fit(X,y,epochs=100,validation_split=0.2,shuffle=True,callbacks=[stop_early,save])\n",
    "model.fit(OX,Oy,\n",
    "          epochs=100,\n",
    "          shuffle=True,\n",
    "          validation_data=(X_val,y_val),\n",
    "          callbacks=[stop_early,save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2116.1333]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1907.5028]], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1909.2122]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2112.9473]], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2115.5286]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1976.9615]], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1453.7723]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1527.852]], dtype=float32)>)\n",
      "\n",
      "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2030.9899]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1980.6711]], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2083.7266]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2091.3213]], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2057.7656]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2056.1714]], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1479.2164]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1561.7834]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "def analyse_game(file,model):\n",
    "    with open(file) as f:\n",
    "        game = chess.pgn.read_game(f)\n",
    "        gt1,gt2 = make_game_tensor(game,num_moves=NUM_MOVES)\n",
    "\n",
    "        #gt = simplify_data_no_eval(gt)\n",
    "        #gt = simplify_data_eval_only(gt)\n",
    "        return model(np.array([gt1]),training=False),model(np.array([gt2]),training=False)\n",
    "    \n",
    "model = keras.models.load_model('modelO1.keras')\n",
    "\n",
    "print(analyse_game(\"data/all_data/2200.pgn\",model))\n",
    "print(analyse_game(\"data/all_data/2000.pgn\",model))\n",
    "print(analyse_game(\"data/all_data/tubby.pgn\",model))\n",
    "print(analyse_game(\"data/all_data/jhudsy.pgn\",model))\n",
    "\n",
    "model = keras.models.load_model('modelOT.keras')\n",
    "\n",
    "print()\n",
    "\n",
    "print(analyse_game(\"data/all_data/2200.pgn\",model))\n",
    "print(analyse_game(\"data/all_data/2000.pgn\",model))\n",
    "print(analyse_game(\"data/all_data/tubby.pgn\",model))\n",
    "print(analyse_game(\"data/all_data/jhudsy.pgn\",model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0\n",
      "count  228946.000000\n",
      "mean     1724.446162\n",
      "std       561.820214\n",
      "min       772.000000\n",
      "25%      1236.000000\n",
      "50%      1725.500000\n",
      "75%      2211.000000\n",
      "max      2686.000000\n",
      "                   0\n",
      "count  228946.000000\n",
      "mean     1591.505840\n",
      "std       292.022961\n",
      "min       772.000000\n",
      "25%      1385.000000\n",
      "50%      1598.000000\n",
      "75%      1799.000000\n",
      "max      2686.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([6818., 4827., 4366., 4475., 4667., 4541., 4323., 4648., 4612.,\n",
       "        4483., 4643., 4297., 4479., 4520., 4532., 4417., 4452., 4541.,\n",
       "        4381., 4427., 4441., 4629., 4401., 4413., 4475., 4647., 4534.,\n",
       "        4482., 4600., 4528., 4521., 4429., 4596., 4495., 4451., 4354.,\n",
       "        4640., 4516., 4806., 4135., 4591., 4852., 4684., 4660., 3785.,\n",
       "        3524., 5643., 2940., 5960., 5765.]),\n",
       " array([ 772.  ,  810.28,  848.56,  886.84,  925.12,  963.4 , 1001.68,\n",
       "        1039.96, 1078.24, 1116.52, 1154.8 , 1193.08, 1231.36, 1269.64,\n",
       "        1307.92, 1346.2 , 1384.48, 1422.76, 1461.04, 1499.32, 1537.6 ,\n",
       "        1575.88, 1614.16, 1652.44, 1690.72, 1729.  , 1767.28, 1805.56,\n",
       "        1843.84, 1882.12, 1920.4 , 1958.68, 1996.96, 2035.24, 2073.52,\n",
       "        2111.8 , 2150.08, 2188.36, 2226.64, 2264.92, 2303.2 , 2341.48,\n",
       "        2379.76, 2418.04, 2456.32, 2494.6 , 2532.88, 2571.16, 2609.44,\n",
       "        2647.72, 2686.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(Oy)\n",
    "print(df.describe())\n",
    "\n",
    "df = pd.DataFrame(y)\n",
    "print(df.describe())\n",
    "\n",
    "#plot the distribution of the ratings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(Oy,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1950 is out of bounds for axis 1 with size 48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/OneDrive - University of Aberdeen/ownCloud/scratch/chesspredict/.venv/lib/python3.12/site-packages/keras/src/utils/numerical_utils.py:99\u001b[0m, in \u001b[0;36mto_categorical\u001b[0;34m(x, num_classes)\u001b[0m\n\u001b[1;32m     97\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     98\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size, num_classes))\n\u001b[0;32m---> 99\u001b[0m \u001b[43mcategorical\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    100\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m input_shape \u001b[38;5;241m+\u001b[39m (num_classes,)\n\u001b[1;32m    101\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(categorical, output_shape)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1950 is out of bounds for axis 1 with size 48"
     ]
    }
   ],
   "source": [
    "len(tf.keras.utils.to_categorical(y1,num_classes=48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 13.  0. 13.  0.]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=10_000)\n",
    "for i in range(40):\n",
    "    print(X[1][i]-X[17][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11.   9.  10.  12.  13.  10.   9.  11.   8.   8.   8.   8.   8.   8.\n",
      "   8.   8.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "   4.   2.   3.   5.   6.   3.   2.   4.  11.   9.  10.  12.  13.  10.\n",
      "   9.  11.   8.   8.   8.   8.   8.   8.   8.   8.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   1.   1.   1.   1.   1.   1.   1.   1.   4.   2.   3.   5.   6.   3.\n",
      "   2.   4.  30. 300. 300. 300.  -3.   0.  -3.   0.]\n"
     ]
    }
   ],
   "source": [
    "print(X[1][30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
